{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport os\nimport glob\nimport cv2\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nimport torch.cuda.amp as amp\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport gc\nimport json\n\nfrom matplotlib import pyplot as plt\nfrom tqdm.notebook import tqdm\n\nsys.path.append('/kaggle/input/timm-clone/pytorch-image-models/') # timm 경로 명시\ndevice = \"cuda\" if torch.cuda.is_available() else 'cpu'\n\nimport timm","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:37:42.112041Z","iopub.execute_input":"2023-06-29T05:37:42.112429Z","iopub.status.idle":"2023-06-29T05:37:48.237028Z","shell.execute_reply.started":"2023-06-29T05:37:42.112399Z","shell.execute_reply":"2023-06-29T05:37:48.235823Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\n#-- configure ---------------------------------------------\n\norgan_threshold = {\n    'Hubmap': {\n        'kidney'        : 0.40,\n        'prostate'      : 0.40,\n        'largeintestine': 0.40,\n        'spleen'        : 0.40,\n        'lung'          : 0.10,\n    },\n    'HPA': {\n        'kidney'        : 0.50,\n        'prostate'      : 0.50,\n        'largeintestine': 0.50,\n        'spleen'        : 0.50,\n        'lung'          : 0.10,\n    },\n}\n\nargs = {\n    'batch_size' : 1,\n    'image_size' : 768\n}\n\nsubmit_type = 'cv' # 'submission'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-29T05:37:48.239357Z","iopub.execute_input":"2023-06-29T05:37:48.239781Z","iopub.status.idle":"2023-06-29T05:37:48.248049Z","shell.execute_reply.started":"2023-06-29T05:37:48.239740Z","shell.execute_reply":"2023-06-29T05:37:48.246862Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class UNetDecoder(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.upsample = nn.Upsample(scale_factor = 2, mode = 'bilinear', align_corners=True)\n        self.block1 = nn.Sequential(\n            nn.Conv2d(in_channels = dim, out_channels = dim // 2, kernel_size = 3, padding = \"same\"),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = dim // 2 , out_channels = dim // 2, kernel_size = 3, padding = \"same\"),\n            nn.ReLU()\n        )\n        self.block2 = nn.Sequential(\n            nn.Conv2d(in_channels = dim // 2, out_channels= dim // 4, kernel_size = 3, padding = \"same\"),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = dim // 4, out_channels= dim // 4, kernel_size = 3, padding = \"same\"),\n            nn.ReLU()\n        )\n        self.block3 = nn.Sequential(\n            nn.Conv2d(in_channels = dim // 4, out_channels = dim // 8, kernel_size = 3, padding = \"same\"),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = dim // 8, out_channels= dim // 8, kernel_size = 3, padding = \"same\"),\n            nn.ReLU()\n        )\n        self.last_conv = nn.Conv2d(in_channels = dim // 8, out_channels = 1, kernel_size = 1)\n    def forward(self, x):\n    #TODO Skip Connection\n        x = self.upsample(x)\n        x = self.block1(x)\n        x = self.upsample(x)\n        x = self.block2(x)\n        x = self.upsample(x)\n        x = self.block3(x)\n        x = self.last_conv(x)\n        #x = F.interpolate(x, size=(720,720))\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:37:48.251328Z","iopub.execute_input":"2023-06-29T05:37:48.251733Z","iopub.status.idle":"2023-06-29T05:37:48.268590Z","shell.execute_reply.started":"2023-06-29T05:37:48.251705Z","shell.execute_reply":"2023-06-29T05:37:48.267120Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = timm.create_model('efficientnet_b4', # 모델 이름\n                                         pretrained = False, # 전이학습(imagenet과 같은 dataset으로 사전 훈련된 weights를 불러옴)\n                                         num_classes = 0,   # 마지막 linear layer 제거\n                                         global_pool = '')  # pooling 제거\n        \n        dim = self.encoder.conv_head.out_channels # effnet_b4 = 1792\n        self.decoder = UNetDecoder(dim = dim)\n\n    def forward(self, batch):\n        x = self.encoder(batch['image'])\n        logit = self.decoder(x)\n        \n        out = {}\n        \n        if self.training :\n            out['bce_loss'] = F.binary_cross_entropy_with_logits(input=logit, target = batch['mask'])\n\n        else :\n            #out['bce_loss'] = F.binary_cross_entropy_with_logits(input=logit, target = batch['mask'])\n            out['probability'] = torch.sigmoid(logit)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:37:48.272075Z","iopub.execute_input":"2023-06-29T05:37:48.272990Z","iopub.status.idle":"2023-06-29T05:37:48.287119Z","shell.execute_reply.started":"2023-06-29T05:37:48.272945Z","shell.execute_reply":"2023-06-29T05:37:48.286261Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"if submit_type == 'cv':\n    valid_file = '../input/hubmap-organ-segmentation/train.csv'\n\nif submit_type == 'submission':\n    valid_file = '../input/hubmap-organ-segmentation/test.csv'\n\n    \n\n\nvalid_df = pd.read_csv(valid_file)\n#valid_df.loc[:,'img_area']=valid_df['img_height']*valid_df['img_width']\nvalid_df  = valid_df.sort_values('id')\n\nvalid_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:37:48.288577Z","iopub.execute_input":"2023-06-29T05:37:48.290543Z","iopub.status.idle":"2023-06-29T05:37:48.746721Z","shell.execute_reply.started":"2023-06-29T05:37:48.290500Z","shell.execute_reply":"2023-06-29T05:37:48.745388Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"      id           organ data_source  img_height  img_width  pixel_size  \\\n302   62          kidney         HPA        3000       3000         0.4   \n35   127            lung         HPA        3000       3000         0.4   \n48   144          spleen         HPA        3000       3000         0.4   \n70   164          kidney         HPA        3000       3000         0.4   \n107  203  largeintestine         HPA        3000       3000         0.4   \n\n     tissue_thickness                                                rle  \\\n302                 4  4382055 23 4385050 34 4388048 44 4391045 57 43...   \n35                  4  4237495 6 4240494 9 4243491 14 4246490 17 4249...   \n48                  4  1273039 14 1276037 18 1279035 23 1282034 26 12...   \n70                  4  1539720 16 1542718 22 1545717 25 1548716 33 15...   \n107                 4  610617 10 613607 28 616602 38 619600 43 622597...   \n\n      age     sex  \n302  59.0    Male  \n35   21.0    Male  \n48   50.0  Female  \n70   61.0    Male  \n107  84.0  Female  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>organ</th>\n      <th>data_source</th>\n      <th>img_height</th>\n      <th>img_width</th>\n      <th>pixel_size</th>\n      <th>tissue_thickness</th>\n      <th>rle</th>\n      <th>age</th>\n      <th>sex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>302</th>\n      <td>62</td>\n      <td>kidney</td>\n      <td>HPA</td>\n      <td>3000</td>\n      <td>3000</td>\n      <td>0.4</td>\n      <td>4</td>\n      <td>4382055 23 4385050 34 4388048 44 4391045 57 43...</td>\n      <td>59.0</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>127</td>\n      <td>lung</td>\n      <td>HPA</td>\n      <td>3000</td>\n      <td>3000</td>\n      <td>0.4</td>\n      <td>4</td>\n      <td>4237495 6 4240494 9 4243491 14 4246490 17 4249...</td>\n      <td>21.0</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>144</td>\n      <td>spleen</td>\n      <td>HPA</td>\n      <td>3000</td>\n      <td>3000</td>\n      <td>0.4</td>\n      <td>4</td>\n      <td>1273039 14 1276037 18 1279035 23 1282034 26 12...</td>\n      <td>50.0</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>164</td>\n      <td>kidney</td>\n      <td>HPA</td>\n      <td>3000</td>\n      <td>3000</td>\n      <td>0.4</td>\n      <td>4</td>\n      <td>1539720 16 1542718 22 1545717 25 1548716 33 15...</td>\n      <td>61.0</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>203</td>\n      <td>largeintestine</td>\n      <td>HPA</td>\n      <td>3000</td>\n      <td>3000</td>\n      <td>0.4</td>\n      <td>4</td>\n      <td>610617 10 613607 28 616602 38 619600 43 622597...</td>\n      <td>84.0</td>\n      <td>Female</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def do_local_validation():\n    submit_df = pd.read_csv('./submission.csv').fillna('')\n    submit_df = submit_df.sort_values('id')\n    truth_df  = valid_df.sort_values('id')\n    \n    lb_score = []\n    num = len(submit_df)\n    for i in range(num):\n        t_df = truth_df.iloc[i]\n        p_df = submit_df.iloc[i]\n        t = rle_decode(t_df.rle, t_df.img_height, t_df.img_width, 1)\n        p = rle_decode(p_df.rle, t_df.img_height, t_df.img_width, 1)\n        \n        dice = 2*(t*p).sum()/(p.sum()+t.sum())\n        lb_score.append(dice)\n        \n    truth_df.loc[:,'lb_score']=lb_score\n    for organ in ['all', 'kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n        if organ != 'all':\n            d = truth_df[truth_df.organ == organ]\n        else:\n            d = truth_df\n        print('\\t%f\\t%s\\t%f' % (len(d) / len(truth_df), organ, d.lb_score.mean()))","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:37:48.748417Z","iopub.execute_input":"2023-06-29T05:37:48.748830Z","iopub.status.idle":"2023-06-29T05:37:48.760283Z","shell.execute_reply.started":"2023-06-29T05:37:48.748792Z","shell.execute_reply":"2023-06-29T05:37:48.758950Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class segDataset(Dataset):   \n    def __init__(self, df, augment, submit_type):\n        self.df = df              \n        self.augment = augment    \n        self.submit_type = submit_type\n\n    def __len__(self): \n        return len(self.df)\n\n    def __getitem__(self, index): \n        d = self.df.iloc[index]\n        id = d['id']\n        height = d['img_height']\n        width = d['img_width']\n        if self.submit_type == 'cv':\n            tiff_dir   = '../input/hubmap-organ-segmentation/train_images'\n            \n        if self.submit_type == 'sub':\n            tiff_dir   = '../input/hubmap-organ-segmentation/test_images'\n         \n        image = cv2.imread(f'{tiff_dir}/{id}.tiff') \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # \n        image = cv2.resize(image, dsize=(args['image_size'], args['image_size']))\n        image = image / 255.  \n\n        out = {}\n        out['id']    = d['id']\n        out['image'] = torch.tensor(image).permute(2,0,1).float() # h, w, c -> c, h, w\n        #out['mask']  = torch.tensor(mask>0.5).float()\n        out['data_source'] = d['data_source']\n        out['organ']  = d['organ']\n        out['height'] = d['img_height']\n        out['width']  = d['img_width']\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:37:48.762054Z","iopub.execute_input":"2023-06-29T05:37:48.762643Z","iopub.status.idle":"2023-06-29T05:37:48.778228Z","shell.execute_reply.started":"2023-06-29T05:37:48.762603Z","shell.execute_reply":"2023-06-29T05:37:48.776838Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"valid_ds = segDataset(df = valid_df, augment = None, submit_type = submit_type)\n\nvalid_dl = DataLoader(valid_ds,\n                batch_size = args['batch_size'],\n                shuffle = False,\n                pin_memory = True,\n                drop_last = False\n                )","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:37:48.780004Z","iopub.execute_input":"2023-06-29T05:37:48.780437Z","iopub.status.idle":"2023-06-29T05:37:48.792674Z","shell.execute_reply.started":"2023-06-29T05:37:48.780404Z","shell.execute_reply":"2023-06-29T05:37:48.791545Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"model = Net()","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:37:48.796558Z","iopub.execute_input":"2023-06-29T05:37:48.796917Z","iopub.status.idle":"2023-06-29T05:37:49.619533Z","shell.execute_reply.started":"2023-06-29T05:37:48.796876Z","shell.execute_reply":"2023-06-29T05:37:49.618560Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_path = [\n    '/kaggle/input/hubmap-src/model/ep_19_unet_model.pt'\n]","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:40:44.211022Z","iopub.execute_input":"2023-06-29T05:40:44.211412Z","iopub.status.idle":"2023-06-29T05:40:44.216395Z","shell.execute_reply.started":"2023-06-29T05:40:44.211382Z","shell.execute_reply":"2023-06-29T05:40:44.215515Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"models = []\nfor i in range(len(model_path)):\n    model.load_state_dict(torch.load(model_path[i])) # weight 불러오기\n    model.eval()\n    model.to(device)\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:51:43.299203Z","iopub.execute_input":"2023-06-29T05:51:43.299664Z","iopub.status.idle":"2023-06-29T05:51:43.385313Z","shell.execute_reply.started":"2023-06-29T05:51:43.299630Z","shell.execute_reply":"2023-06-29T05:51:43.383580Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m models \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(model_path)):\n\u001b[0;32m----> 3\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# weight 불러오기\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/ep-19-unet'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/ep-19-unet'","output_type":"error"}]},{"cell_type":"code","source":"def rle_encode(img):\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(rle, width, height, fill=1, dtype=np.float32):\n    s = rle.split()\n    start  = np.asarray(s[0::2], dtype=int)-1\n    length = np.asarray(s[1::2], dtype=int)\n    end = start + length\n    image = np.zeros(height * width, dtype=dtype)\n    for s, e in zip(start, end):\n        image[s:e] = fill\n    image = image.reshape(height, width) #.T\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:37:50.397549Z","iopub.status.idle":"2023-06-29T05:37:50.398274Z","shell.execute_reply.started":"2023-06-29T05:37:50.397952Z","shell.execute_reply":"2023-06-29T05:37:50.397984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"results = []\n\nfor i,d in tqdm(enumerate(valid_dl), total=len(valid_dl)):    \n    cnt  = 0\n    prob = 0\n    TTA  = False # Test Time Augmentation\n    with torch.no_grad():\n        with amp.autocast(enabled = True):\n            d['image'] = d['image'].to(device)\n            \n            for i in range(len(models)):\n                cnt += 1\n                output = models[i](d)\n\n                prob += \\\n                F.interpolate(output['probability'], size=(d['height'], d['width']),\n                              mode='bilinear',align_corners=False, antialias=True)\n                \n                #if TTA == True:\n                    \n            prob /= cnt\n    prob = prob.detach().cpu().numpy() > 0.5\n    rle  = rle_encode(prob.T)\n    results.append({'id':d['id'].detach().cpu().numpy(), 'rle':rle})\n    submit_df = pd.DataFrame(results)\n    submit_df.to_csv('submission.csv',index=False)\n\nsubmit_df","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:37:50.400378Z","iopub.status.idle":"2023-06-29T05:37:50.401622Z","shell.execute_reply.started":"2023-06-29T05:37:50.401359Z","shell.execute_reply":"2023-06-29T05:37:50.401384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Local Validation","metadata":{}},{"cell_type":"code","source":"def do_local_validation():\n    submit_df = pd.read_csv('./submission.csv').fillna('')\n    submit_df = submit_df.sort_values('id')\n    truth_df  = valid_df.sort_values('id')\n    \n    lb_score = []\n    num = len(submit_df)\n    for i in tqdm(range(num)):\n        t_df = truth_df.iloc[i]\n        p_df = submit_df.iloc[i]\n        t = rle_decode(t_df.rle, t_df.img_height, t_df.img_width, 1)\n        p = rle_decode(p_df.rle, t_df.img_height, t_df.img_width, 1)\n        \n        dice = 2*(t*p).sum()/(p.sum()+t.sum())\n        lb_score.append(dice)\n    \n    truth_df.loc[:,'lb_score']=lb_score\n    for organ in ['all', 'kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n        if organ != 'all':\n            d = truth_df[truth_df.organ == organ]\n        else:\n            d = truth_df\n        print('\\t%f\\t%s\\t%f' % (len(d) / len(truth_df), organ, d.lb_score.mean()))","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:37:50.403087Z","iopub.status.idle":"2023-06-29T05:37:50.403758Z","shell.execute_reply.started":"2023-06-29T05:37:50.403523Z","shell.execute_reply":"2023-06-29T05:37:50.403562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"do_local_validation()","metadata":{"execution":{"iopub.status.busy":"2023-06-29T05:37:50.405520Z","iopub.status.idle":"2023-06-29T05:37:50.405919Z","shell.execute_reply.started":"2023-06-29T05:37:50.405732Z","shell.execute_reply":"2023-06-29T05:37:50.405749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}